# Unified Agent Architecture Brainstorm: Hanachan Core

> **Status:** Finalized Vision Statement  
> **Philosophy:** "System Governance, LLM Reasoning"  
> **Core Principle:** The LLM is a reasoning worker in a system-controlled sandbox. It never decides access, memory fate, or policy.

---

## 1. Big Picture Mental Model

An agent system is **not** one LLM loop. It is a **governed reasoning system**:

```
Intent → Context Assembly → Reasoning → Action Proposal → Policy Check → Execution → Memory Update
```

- **LLM reasons**
- **System decides what is allowed**
- **Soft inside (LLM), hard outside (system)**

---

## 2. Manifest vs. Policy (Critical Distinction)

| Concept | Definition | Analogy |
| :--- | :--- | :--- |
| **Manifest** | WHAT EXISTS: A catalog of capabilities (Tools, Specialists, Intents). | Restaurant menu / API Docs |
| **Policy** | WHAT IS ALLOWED: Rules deciding whether something can be done now by whom. | Health inspection / Age check |

- **Manifest** answers: *What tools exist? What inputs do they have?*
- **Policy** answers: *Can this agent call this tool? Is the rate limit exceeded?*

---

## 3. The Core Split: Internal vs. External

The system maintains a hard boundary between **Internal Logic** (deterministic, system-owned) and **External Reasoning** (LLM-driven).

### 3.1 The "Aperture" (Context Assembly)
The LLM never queries databases directly. The System (Internal) uses a "Context Assembly" engine to gather data and present it as a "Soft" narrative context.
- **LLM sees:** "The user is struggling with 'wa' particle and is at N4 level."
- **LLM does NOT see:** SQL queries, Mongo IDs, or NRS API endpoint results.

### 3.2 Guard Layer & Policy Engine
They do **NOT** live inside the LLM. They sit **between reasoning and execution**:
```
LLM → (Action Proposal) → Policy Engine → Tool Executor
```

---

## 4. Resource vs. Artifact vs. Memory

### 4.1 Data Definitions
| Entity | **Resource** (Inbound) | **Artifact** (Outbound) |
| :--- | :--- | :--- |
| **Origin** | External (Uploaded PDFs, Docs, URLs) | Internal (Generated by Agent tools) |
| **Service** | Handles by **NRS** (Neural Resource Service) | Handles by **ArtifactService** |
| **Access** | Scoped by `resource_ids` | Scoped by `artifact_id` |

### 4.2 RAG vs. Memory (The Distinction)
| Aspect | RAG (Resources) | Memory (Episodic/Semantic) |
| :--- | :--- | :--- |
| **Purpose** | External knowledge | Agent experience |
| **Mutability** | Read-only | Read/write |
| **Ownership** | System / Corpus | User / Agent |
| **Lifetime** | Static | Grows over time |

- **RAG answers:** "What does the world know?"
- **Memory answers:** "What do I know from experience?"

---

## 5. Context Assembly Engine (The Intelligence Layer)

Context is **selective**, not a "dump."

1. **Intent Extraction**: System identifies user goal (e.g., "Grammar Practice").
2. **Policy Filter**: System checks: "What is this user allowed to see?"
3. **Retrieval Planning**: 
    - Pull **Resources** (Genki PDF) via similarity.
    - Pull **Artifacts** (Past Quizzes) via user history.
    - Pull **Memory** (Facts) via semantic relations.
4. **Summarization/Compression**: System distills internal data into a concise "Situation Report" to lower token cost and prevent hallucinations.
5. **Prompt Delivery**: LLM receives the report + user message.

---

## 6. Memory Types & Governance

### 6.1 Memory Breakdown
- **Episodic**: Past interactions and behavior traces.
- **Semantic**: Stable facts, knowledge graph, and user preferences.
- **Artifact**: History of work produced (quizzes, flashcards).

### 6.2 System-First Writing
**Golden Rule:** Memory is queried, not dumped.
- **LLM Proposal**: LLM can suggest "I should remember this."
- **System Decision**: The **Policy Engine** verifies against rules (Pattern matching).
- **LLM does NOT control:** `is_memorable` or `scope` (Permanent vs Session).

---

## 7. Loop Control (The Auto-Loop)

Loops are **System-owned**.

```python
while system.budget_allows:
    context = assemble_context(intent)
    proposal = LLM.invocate(context)
    if proposal.requests_action:
        policy = check_policy(proposal.action, user_role)
        if policy.allowed:
            result = execute(proposal.action)
            update_context(result)
        else:
            handle_denial(policy.reason)
    else:
        break
```

---

## 8. Design Rules for Agent Coders

1. **Never trust the LLM with authority.** (Policy must be hard-coded or schema-driven).
2. **Everything callable must be declared.** (The Manifest is the source of truth).
3. **Everything executable must pass policy.** (User-specific gating).
4. **Memory is queried, not dumped.** (Use RAG techniques for LTM).
5. **Loops are system-owned.** (LLM cannot decide to run indefinitely).
6. **Soft inside (LLM Reasoning), hard outside (System Structure).**

---

## 9. Migration Roadmap

1. **Phase 1: Declarative Config**
    - Move `HanachanAgent.tools` to `manifest.yaml`.
    - Move User Roles to `policy.yaml`.
2. **Phase 2: The Context Assembler**
    - Build the `Aperture` class to hide internal logic.
    - Replace raw database calls in `core_agent.py` with the Assembler.
3. **Phase 3: Governance Swap**
    - Replace LLM `MemoryEvaluator` with Regex-based `PolicyEngine` checks.
    - Implement the "Internal Knowledge Graph Update" trigger.

---

## 10. Minimal Reference Architecture
```
User → Intent Interpreter → Context Assembly Engine → LLM Reasoning → Action Proposal → Policy Engine → Tool Executor → Memory Update
```
