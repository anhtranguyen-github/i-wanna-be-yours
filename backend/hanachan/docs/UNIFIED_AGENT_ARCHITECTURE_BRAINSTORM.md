# Unified Agent Architecture Brainstorm: Hanachan Core

> **Status:** Finalized Vision Statement  
> **Philosophy:** "System Governance, LLM Reasoning"  
> **Core Principle:** The LLM is a reasoning worker in a system-controlled sandbox. It never decides access, memory fate, or policy.

---

## 1. The Core Split: Internal vs. External

The system maintains a hard boundary between **Internal Logic** (deterministic, system-owned) and **External Reasoning** (LLM-driven).

### 1.1 The "Aperture" (Context Assembly)
The LLM never queries databases directly. The System (Internal) uses a "Context Assembly" engine to gather data and present it as a "Soft" narrative context.
- **LLM sees:** "The user is struggling with 'wa' particle and is at N4 level."
- **LLM does NOT see:** SQL queries, Mongo IDs, or NRS API endpoint results.

---

## 2. Resource vs. Artifact (The Data Boundary)

| Entity | **Resource** (Inbound) | **Artifact** (Outbound) |
| :--- | :--- | :--- |
| **Origin** | External (Uploaded PDFs, Docs, URLs) | Internal (Generated by Agent tools) |
| **Service** | Handles by **NRS** (Neural Resource Service) | Handles by **ArtifactService** |
| **LTM Role** | Static "Input" for RAG / Context | Dynamic "Output" of reasoning history |
| **Storage** | Vector DB (Qdrant) + Metadata | Document Store (MongoDB) |
| **Access** | Scoped by `resource_ids` | Scoped by `artifact_id` or `type` |

---

## 3. Manifest vs. Policy (The Governance Model)

### 3.1 The Manifest (What EXISTS)
A declarative catalog of capabilities.
- **Tools**: List of functions, their I/O schemas, and whether they produce **Artifacts**.
- **Specialists**: Sub-agent personas (Sensei, Mentor, etc.) and the intents they handle.
- **Intents**: Deterministic patterns (Regex/Keywords) used to trigger workflows.

### 3.2 The Policy (What is ALLOWED)
The "Law" of the system, enforced by the **Policy Engine**.
- **Hierarchy**:
    1. **Identity**: Is user Premium? (Level 1: Role-based access).
    2. **Permission**: Does Role X have access to Tool Y? (Level 2: Capability check).
    3. **Governance**: Is the LLM trying to bypass memory rules? (Level 3: Logic check).
- **Core Memory Rule**: LLM cannot decide `is_memorable` or `scope`. The System uses pattern-matching (Internal) to decide what moves to permanent memory.

---

## 4. Context Assembly Engine (The Intelligence Layer)

Context is **selective**, not a "dump."

1. **Intent Extraction**: System identifies user goal (e.g., "Grammar Practice").
2. **Policy Filter**: System checks: "What is this user allowed to see?"
3. **Retrieval Planning**: 
    - Pull **Resources** (Genki PDF) via similarity.
    - Pull **Artifacts** (Past Quizzes) via user history.
    - Pull **Memory** (Facts) via semantic relations.
4. **Distillation**: System summarizes internal data into a concise "Situation Report" for the LLM.
5. **Prompt Delivery**: LLM receives the report + user message.

---

## 5. Memory Types & Governance

### 5.1 Short-Term Memory (STM)
- **Scope**: Current Conversation.
- **Storage**: PostgreSQL.
- **Rule**: Always injected for continuity.

### 5.2 Long-Term Memory (LTM)
- **Episodic**: "What happened." (Scanned by system for patterns).
- **Semantic**: "Facts & Entities." (Updated by system when certain keywords appear).
- **Artifact/Record**: "Work history." (Accessed via specific tools/intents).

### 5.3 System-First Writing
- **LLM Proposal**: LLM can suggest "I should remember this."
- **System Decision**: The **Policy Engine** verifies against rules. 
    - If the user said "My job is X", the System pattern matcher triggers a Neo4j update. 
    - The LLM cannot "force" a save or "force" a delete.

---

## 6. Loop Control (The Auto-Loop)

Loops are **System-owned**.
```python
while system.budget_allows:
    context = assemble_context(intent)
    proposal = LLM.invocate(context)
    if proposal.action:
        policy = check_policy(proposal.action, user_role)
        if policy.denied:
            inform_llm(policy.reason)
            continue
        result = execute_action(proposal.action)
        update_context(result)
    else:
        deliver_response(proposal.text)
        break
```

---

## 7. Migration Roadmap

1. **Phase 1: Declarative Config**
    - Move `HanachanAgent.tools` to `manifest.yaml`.
    - Move User Roles to `policy.yaml`.
2. **Phase 2: The Context Assembler**
    - Build the `Aperture` class to hide internal logic.
    - Replace raw database calls in `core_agent.py` with the Assembler.
3. **Phase 3: Governance Swap**
    - Replace LLM `MemoryEvaluator` with Regex-based `PolicyEngine` checks.
    - Implement the "Internal Knowledge Graph Update" trigger.

---

## 8. Final Vision One-Liner

> "Hanachan is a secure operating system for Japanese learning, where the LLM is the interface, but the System is the Authority."
